import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

def main():
    print("üîé Solicitando p√°gina de Infaoliva...")
    url = "https://www.infaoliva.com/"
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"‚ùå Error al acceder a la p√°gina de Infaoliva: {e}")
        exit(1)

    soup = BeautifulSoup(response.text, 'html.parser')
    
    print("üß™ Buscando tabla de precios...")
    table = soup.find("table")
    if not table:
        print("‚ùå No se encontr√≥ la tabla de precios.")
        exit(1)

    rows = table.find_all("tr")
    precios = {}

    for row in rows[1:]:
        cols = row.find_all("td")
        if len(cols) == 3:
            tipo = cols[0].text.strip()
            variedad = cols[1].text.strip()
            precio_raw = cols[2].text.strip().replace(".", "").replace(",", ".").replace("‚Ç¨", "").strip()
            try:
                precio = float(precio_raw)
                precios[tipo] = {
                    "variedad": variedad,
                    "precio_eur_kg": precio
                }
            except ValueError:
                continue

    if not precios:
        print("‚ùå No se encontr√≥ un precio v√°lido en el contenido.")
        exit(1)

    datos = {
        "fuente": "Infaoliva",
        "fecha": datetime.now().strftime("%Y-%m-%d"),
        "precios": precios,
        "ultima_actualizacion": datetime.utcnow().isoformat()  # ‚¨ÖÔ∏è Esto fuerza que el JSON siempre cambie
    }

    with open("precio-aceite.json", "w", encoding="utf-8") as f:
        json.dump(datos, f, indent=4, ensure_ascii=False)

    print("‚úÖ Precios extra√≠dos correctamente y guardados en 'precio-aceite.json'.")

if __name__ == "__main__":
    main()
